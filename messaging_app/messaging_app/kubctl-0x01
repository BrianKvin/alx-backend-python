#!/bin/bash

# kubctl-0x01 - Kubernetes Django App Scaling Script
# This script scales Django app, performs load testing, and monitors resources

set -e  # Exit on any error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
MAGENTA='\033[0;35m'
NC='\033[0m' # No Color

# Function to print colored output
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_header() {
    echo -e "${CYAN}$1${NC}"
}

print_metric() {
    echo -e "${MAGENTA}[METRIC]${NC} $1"
}

# Configuration
APP_NAME="django-messaging-app"
SERVICE_NAME="django-messaging-service"
NAMESPACE="default"
TARGET_REPLICAS=3
LOAD_TEST_DURATION="30s"
LOAD_TEST_THREADS=4
LOAD_TEST_CONNECTIONS=10

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to install wrk if not present
install_wrk() {
    print_status "Installing wrk load testing tool..."
    
    # Detect OS
    OS=$(uname -s)
    
    case $OS in
        "Linux")
            if command_exists apt-get; then
                sudo apt-get update && sudo apt-get install -y wrk
            elif command_exists yum; then
                sudo yum install -y wrk
            elif command_exists dnf; then
                sudo dnf install -y wrk
            elif command_exists pacman; then
                sudo pacman -S --noconfirm wrk
            else
                print_error "Cannot install wrk automatically. Please install it manually."
                exit 1
            fi
            ;;
        "Darwin")
            if command_exists brew; then
                brew install wrk
            else
                print_error "Homebrew not found. Please install wrk manually or install Homebrew first."
                exit 1
            fi
            ;;
        *)
            print_error "Unsupported operating system: $OS"
            exit 1
            ;;
    esac
    
    print_success "wrk installed successfully!"
}

# Function to check prerequisites
check_prerequisites() {
    print_status "Checking prerequisites..."
    
    # Check if kubectl is available
    if ! command_exists kubectl; then
        print_error "kubectl is not installed. Please install it first."
        exit 1
    fi
    
    # Check if wrk is available
    if ! command_exists wrk; then
        print_warning "wrk not found. Installing..."
        install_wrk
    else
        print_success "wrk is already installed"
    fi
    
    # Check if minikube is running
    if ! minikube status >/dev/null 2>&1; then
        print_error "Minikube is not running. Please start it first with: minikube start"
        exit 1
    fi
    
    # Enable metrics server if not already enabled
    if ! minikube addons list | grep "metrics-server" | grep -q "enabled"; then
        print_status "Enabling metrics server..."
        minikube addons enable metrics-server
        print_success "Metrics server enabled"
        
        # Wait for metrics server to be ready
        print_status "Waiting for metrics server to be ready..."
        kubectl wait --for=condition=available --timeout=120s deployment/metrics-server -n kube-system
    fi
    
    print_success "All prerequisites met"
}

# Function to check if deployment exists
check_deployment_exists() {
    if ! kubectl get deployment $APP_NAME >/dev/null 2>&1; then
        print_error "Deployment '$APP_NAME' not found. Please deploy the app first using deployment.yaml"
        exit 1
    fi
    print_success "Deployment '$APP_NAME' found"
}

# Function to get current replica count
get_current_replicas() {
    kubectl get deployment $APP_NAME -o jsonpath='{.spec.replicas}'
}

# Function to scale the deployment
scale_deployment() {
    print_header "=== SCALING DEPLOYMENT ==="
    
    CURRENT_REPLICAS=$(get_current_replicas)
    print_status "Current replica count: $CURRENT_REPLICAS"
    
    if [[ "$CURRENT_REPLICAS" -eq "$TARGET_REPLICAS" ]]; then
        print_warning "Deployment already has $TARGET_REPLICAS replicas"
    else
        print_status "Scaling deployment to $TARGET_REPLICAS replicas..."
        kubectl scale deployment $APP_NAME --replicas=$TARGET_REPLICAS
        print_success "Scaling command issued"
    fi
    
    # Wait for rollout to complete
    print_status "Waiting for deployment rollout to complete..."
    kubectl rollout status deployment/$APP_NAME --timeout=300s
    
    print_success "Deployment scaled successfully to $TARGET_REPLICAS replicas"
}

# Function to verify pods are running
verify_pods() {
    print_header "=== VERIFYING PODS ==="
    
    print_status "Current pod status:"
    kubectl get pods -l app=$APP_NAME -o wide
    
    # Count ready pods
    READY_PODS=$(kubectl get pods -l app=$APP_NAME --field-selector=status.phase=Running -o jsonpath='{.items[*].metadata.name}' | wc -w)
    print_metric "Ready pods: $READY_PODS/$TARGET_REPLICAS"
    
    if [[ "$READY_PODS" -eq "$TARGET_REPLICAS" ]]; then
        print_success "All $TARGET_REPLICAS pods are running successfully"
    else
        print_warning "Only $READY_PODS out of $TARGET_REPLICAS pods are ready"
    fi
    
    # Show pod distribution across nodes
    echo ""
    print_status "Pod distribution across nodes:"
    kubectl get pods -l app=$APP_NAME -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName,STATUS:.status.phase
}

# Function to setup port forwarding
setup_port_forward() {
    print_status "Setting up port forwarding for load testing..."
    
    # Kill any existing port-forward processes
    pkill -f "kubectl port-forward" || true
    sleep 2
    
    # Start port forwarding in background
    kubectl port-forward service/$SERVICE_NAME 8080:80 > /dev/null 2>&1 &
    PORT_FORWARD_PID=$!
    
    # Wait for port forwarding to be ready
    sleep 5
    
    # Test if port forwarding is working
    if curl -s http://localhost:8080 >/dev/null 2>&1; then
        print_success "Port forwarding established on http://localhost:8080"
        return 0
    else
        print_warning "Port forwarding may not be ready yet, continuing anyway..."
        return 0
    fi
}

# Function to perform load testing
perform_load_test() {
    print_header "=== LOAD TESTING ==="
    
    setup_port_forward
    
    print_status "Starting load test with wrk..."
    print_status "Duration: $LOAD_TEST_DURATION, Threads: $LOAD_TEST_THREADS, Connections: $LOAD_TEST_CONNECTIONS"
    
    # Create a simple load test script
    cat > /tmp/load_test.lua << 'EOF'
-- Load test script for Django app
wrk.method = "GET"
wrk.headers["User-Agent"] = "wrk-load-test"

function response(status, headers, body)
    if status ~= 200 then
        print("Error: HTTP " .. status)
    end
end
EOF
    
    echo ""
    print_status "Running load test..."
    echo "========================================="
    
    # Run the load test
    wrk -t$LOAD_TEST_THREADS -c$LOAD_TEST_CONNECTIONS -d$LOAD_TEST_DURATION \
        -s /tmp/load_test.lua \
        --latency \
        http://localhost:8080/ || print_warning "Load test completed with some issues"
    
    echo "========================================="
    print_success "Load test completed"
    
    # Clean up
    rm -f /tmp/load_test.lua
    kill $PORT_FORWARD_PID 2>/dev/null || true
}

# Function to monitor resource usage
monitor_resources() {
    print_header "=== RESOURCE MONITORING ==="
    
    print_status "Waiting for metrics to be available..."
    sleep 10
    
    # Monitor node resources
    print_status "Node resource usage:"
    echo "----------------------------------------"
    kubectl top nodes || print_warning "Node metrics not available yet"
    
    echo ""
    
    # Monitor pod resources
    print_status "Pod resource usage for Django app:"
    echo "----------------------------------------"
    kubectl top pods -l app=$APP_NAME || print_warning "Pod metrics not available yet"
    
    echo ""
    
    # Show resource requests and limits
    print_status "Resource requests and limits:"
    echo "----------------------------------------"
    kubectl describe deployment $APP_NAME | grep -A 10 "Requests\|Limits" || print_warning "Could not retrieve resource limits"
}

# Function to show detailed pod information
show_pod_details() {
    print_header "=== DETAILED POD INFORMATION ==="
    
    PODS=$(kubectl get pods -l app=$APP_NAME -o jsonpath='{.items[*].metadata.name}')
    
    for pod in $PODS; do
        echo ""
        print_status "Details for pod: $pod"
        echo "----------------------------------------"
        kubectl get pod $pod -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName,IP:.status.podIP,RESTARTS:.status.containerStatuses[0].restartCount
        
        # Show recent logs (last 5 lines)
        print_status "Recent logs from $pod:"
        kubectl logs $pod --tail=5 2>/dev/null || print_warning "Could not retrieve logs for $pod"
        echo "----------------------------------------"
    done
}

# Function to test load balancing
test_load_balancing() {
    print_header "=== TESTING LOAD BALANCING ==="
    
    setup_port_forward
    
    print_status "Testing if requests are distributed across pods..."
    
    # Make multiple requests and check which pods handle them
    echo "Making 10 test requests to check load distribution:"
    for i in {1..10}; do
        response=$(curl -s http://localhost:8080/ 2>/dev/null || echo "failed")
        if [[ "$response" != "failed" ]]; then
            echo "Request $i: Success"
        else
            echo "Request $i: Failed"
        fi
        sleep 0.5
    done
    
    print_success "Load balancing test completed"
    kill $PORT_FORWARD_PID 2>/dev/null || true
}

# Function to show scaling summary
show_scaling_summary() {
    print_header "=== SCALING SUMMARY ==="
    
    CURRENT_REPLICAS=$(get_current_replicas)
    READY_PODS=$(kubectl get pods -l app=$APP_NAME --field-selector=status.phase=Running -o jsonpath='{.items[*].metadata.name}' | wc -w)
    
    echo "Deployment: $APP_NAME"
    echo "Target Replicas: $TARGET_REPLICAS"
    echo "Current Replicas: $CURRENT_REPLICAS"
    echo "Ready Pods: $READY_PODS"
    echo ""
    
    if [[ "$READY_PODS" -eq "$TARGET_REPLICAS" ]]; then
        print_success "✅ Scaling completed successfully!"
    else
        print_warning "⚠️  Scaling partially completed. $READY_PODS/$TARGET_REPLICAS pods ready."
    fi
    
    echo ""
    print_status "Useful commands for continued monitoring:"
    echo "  kubectl get pods -l app=$APP_NAME"
    echo "  kubectl top pods -l app=$APP_NAME"
    echo "  kubectl logs <pod-name>"
    echo "  kubectl describe pod <pod-name>"
    echo "  kubectl scale deployment $APP_NAME --replicas=<number>"
}

# Function to run continuous monitoring
continuous_monitoring() {
    print_header "=== CONTINUOUS MONITORING ==="
    print_status "Starting continuous monitoring (Press Ctrl+C to stop)..."
    
    trap 'print_status "Stopping continuous monitoring..."; exit 0' INT
    
    while true; do
        clear
        echo "=== REAL-TIME KUBERNETES MONITORING ==="
        echo "Time: $(date)"
        echo ""
        
        echo "PODS:"
        kubectl get pods -l app=$APP_NAME -o wide
        echo ""
        
        echo "RESOURCE USAGE:"
        kubectl top pods -l app=$APP_NAME 2>/dev/null || echo "Metrics not available"
        echo ""
        
        echo "SERVICE:"
        kubectl get service $SERVICE_NAME
        echo ""
        
        echo "Press Ctrl+C to stop monitoring..."
        sleep 5
    done
}

# Main function
main() {
    echo "================================================"
    echo "    Kubernetes Django App Scaling Script"
    echo "               (kubctl-0x01)"
    echo "================================================"
    echo ""
    
    # Check prerequisites
    check_prerequisites
    echo ""
    
    # Check if deployment exists
    check_deployment_exists
    echo ""
    
    # Scale the deployment
    scale_deployment
    echo ""
    
    # Verify pods are running
    verify_pods
    echo ""
    
    # Perform load testing
    perform_load_test
    echo ""
    
    # Monitor resource usage
    monitor_resources
    echo ""
    
    # Show detailed pod information
    show_pod_details
    echo ""
    
    # Test load balancing
    test_load_balancing
    echo ""
    
    # Show scaling summary
    show_scaling_summary
    echo ""
    
    # Ask if user wants continuous monitoring
    read -p "Do you want to start continuous monitoring? (y/n): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        continuous_monitoring
    fi
}

# Handle command line arguments
case "${1:-}" in
    "scale")
        scale_deployment
        verify_pods
        ;;
    "test")
        perform_load_test
        ;;
    "monitor")
        monitor_resources
        ;;
    "continuous")
        continuous_monitoring
        ;;
    "status")
        verify_pods
        show_scaling_summary
        ;;
    *)
        main
        ;;
esac