### README.md

- ### Advanced Python: Generators, Decorators, Context Managers, and Asynchronous Programming
  This project provides a comprehensive exploration of advanced Python programming techniques, including generators, decorators, context managers, and asynchronous programming. These concepts empower developers to write efficient, readable, and maintainable code for scenarios involving large data processing, resource management, and concurrent execution.

### Table of Contents

- Project Overview (#project-overview)
- Learning Objectives (#learning-objectives)
- Key Concepts (#key-concepts)
- Generators (#generators)
- Decorators (#decorators)
- Context Managers (#context-managers)
- Asynchronous Programming (#asynchronous-programming)
- Project Requirements (#project-requirements)
- Tasks (#tasks)
- Task 0: Getting Started with Python Generators (#task-0-getting-started-with-python-generators)
- Task 1: Generator that Streams Rows from an SQL Database (#task-1-generator-that-streams-rows-from-an-sql-database)
- Task 2: Batch Processing Large Data (#task-2-batch-processing-large-data)
- Task 3: Lazy Loading Paginated Data (#task-3-lazy-loading-paginated-data)
- Task 4: Memory-Efficient Aggregation with Generators (#task-4-memory-efficient-aggregation-with-generators)

### Additional Resources (#additional-resources)

### Repository (#repository)

### Project Overview

This project focuses on leveraging Python's advanced features to handle large datasets, manage resources efficiently, and implement concurrent programming. By completing the tasks, you will gain hands-on experience with:

- Creating memory-efficient iterators using generators.
- Modifying function behavior with decorators.
- Managing resources safely with context managers.
- Writing non-blocking, concurrent code using asynchronous programming.
- Integrating Python with SQL databases for dynamic data processing.
- The tasks emphasize practical applications such as streaming data from a MySQL database, batch processing, lazy loading, and computing aggregates efficiently.

### Learning Objectives

### By completing this project, you will:

- Master generators for memory-efficient iterative data processing.
- Use decorators to modify function behavior and promote code reusability.
- Implement context managers to manage resources like files and database connections.
- Write asynchronous code using asyncio for concurrent execution of IO-bound tasks.
- Handle large datasets efficiently using batch processing and lazy loading.
- Integrate Python with SQL databases to fetch and process data dynamically.
- Optimize performance by minimizing memory usage and leveraging Pythonâ€™s yield keyword.

### Key Concepts

- Generators
- Generators are iterators that yield values one at a time, enabling memory-efficient processing and lazy evaluation. They are defined using the yield keyword and are ideal for handling large datasets or streams.

### Key Features:

- Generator Functions: Use yield to produce values incrementally.
- Generator Expressions: Similar to list comprehensions but return generator objects.

### Benefits:

- Memory efficiency by generating one item at a time.
- Lazy evaluation for on-demand computation.

### Example:

python

### Generator Function

def firstn(n):
num = 0
while num < n:
yield num
num += 1

# Generator Expression

squares = (x * x for x in range(10))
Decorators
Decorators are functions that modify the behavior of other functions or methods. They are applied using the @decorator_name syntax and are useful for adding functionality like logging or access control without altering the original code.
Key Features:
Basic Structure: Wraps a function with an inner wrapper function.
Flexible Arguments: Handles varying arguments using *args and \*\*kwargs.
Benefits:
Code reusability across multiple functions.
Separation of concerns for cleaner code.
Example:
python

# Simple Decorator

def decorator(func):
def wrapper():
print("Before function call")
func()
print("After function call")
return wrapper

@decorator
def say_hello():
print("Hello!")

# Decorator with Arguments

def do_twice(func):
def wrapper_do_twice(*args, \*\*kwargs):
func(*args, **kwargs)
func(\*args, **kwargs)
return wrapper_do_twice

@do_twice
def greet(name):
print(f"Hello {name}")
Context Managers
Context managers ensure resources are properly acquired and released, typically using the with statement. They are ideal for managing file operations, network connections, or locks.
Key Features:
Class-based Context Managers: Use **enter** and **exit** methods.
Contextlib-based Context Managers: Use @contextmanager decorator for simpler implementation.
Benefits:
Automatic resource management (e.g., closing files).
Cleaner, more readable code.
Example:
python

# Class-based Context Manager

class File:
def **init**(self, filename, method):
self.file_obj = open(filename, method)

    def __enter__(self):
        return self.file_obj

    def __exit__(self, type, value, traceback):
        self.file_obj.close()

with File('demo.txt', 'w') as f:
f.write('Hello World!')

# Contextlib-based Context Manager

from contextlib import contextmanager

@contextmanager
def open_file(name):
f = open(name, 'w')
try:
yield f
finally:
f.close()

with open_file('demo.txt') as f:
f.write('Hello World!')

### Asynchronous Programming

Asynchronous programming enables non-blocking code execution for concurrent tasks, using Pythonâ€™s asyncio library with async and await keywords. It is ideal for IO-bound tasks like web servers and network communication.

### Key Features:

- Coroutines: Functions defined with async def that can pause and resume.
- Event Loop: Manages execution of coroutines and asynchronous tasks.
- Concurrency with asyncio: Runs multiple coroutines concurrently without multithreading.

### Benefits:

- Improved performance for IO-bound tasks.
- Efficient concurrency without threading overhead.

### Example:

python
import asyncio

### Basic Coroutine

async def greet(name):
print(f"Hello {name}")
await asyncio.sleep(1)
print(f"Goodbye {name}")

asyncio.run(greet("World"))

#### Running Multiple Coroutines

async def main():
await asyncio.gather(
greet("Alice"),
greet("Bob"),
)

asyncio.run(main())

# Project Requirements

- Proficiency in Python 3.x.
- Understanding of yield and generator functions.
- Familiarity with SQL and database operations (MySQL, SQLite).
- Basic knowledge of database schema design and data seeding.
- Ability to use Git and GitHub for version control.

# Tasks

Here's your content rewritten as a clean and professional `README.md` file:

---

# ðŸ“¦ Task 0: Getting Started with Python Generators

## ðŸŽ¯ Objective

Set up a MySQL database and use a Python generator to stream user data rows one by one.

---

## ðŸ“œ Instructions

### ðŸ”§ 1. Create `seed.py` with the following functionality:

#### âœ… Connect to MySQL Server

* **Function:** `connect_db()`
* Connects to the MySQL server.

#### âœ… Create the Database

* **Function:** `create_database()`
* Creates a database named `ALX_prodev` if it doesnâ€™t already exist.

#### âœ… Connect to the `ALX_prodev` Database

* **Function:** `connect_to_prodev()`
* Connects specifically to the `ALX_prodev` database.

#### âœ… Create `user_data` Table

* **Function:** `create_table()`
* Table schema:

  * `user_id` â€“ UUID, **Primary Key**, **Indexed**
  * `name` â€“ `VARCHAR`, **NOT NULL**
  * `email` â€“ `VARCHAR`, **NOT NULL**
  * `age` â€“ `DECIMAL`, **NOT NULL**

#### âœ… Populate Table from CSV

* **Function:** `insert_data()`
* Populates `user_data` table with rows from `user_data.csv`.

---

## ðŸ“¤ Example Output

```bash
connection successful
Table user_data created successfully
Database ALX_prodev is present
[('00234e50-34eb-4ce2-94ec-26e3fa749796', 'Dan Altenwerth Jr.', 'Molly59@gmail.com', 67), ...]
```

---

## ðŸ“‚ Repository Structure

* **GitHub Repository:** `alx-backend-python`
* **Directory:** `python-generators-0x00`
* **Main Script:** `seed.py`

---

---

## ðŸ” Task 1: Generator That Streams Rows from an SQL Database

### ðŸŽ¯ Objective

Create a Python generator that streams rows from the `user_data` table one by one.

---

### ðŸ“œ Instructions

In the file `0-stream_users.py`, implement a function called `stream_users()` that:

* Connects to the `ALX_prodev` MySQL database.
* Fetches all rows from the `user_data` table.
* Yields each row **one at a time** using a generator.
* Contains **no more than one loop** in the function.

---

### ðŸ§ª Example Output

```bash
{'user_id': '00234e50-34eb-4ce2-94ec-26e3fa749796', 'name': 'Dan Altenwerth Jr.', 'email': 'Molly59@gmail.com', 'age': 67}
{'user_id': '006bfede-724d-4cdd-a2a6-59700f40d0da', 'name': 'Glenda Wisozk', 'email': 'Miriam21@gmail.com', 'age': 119}
...
```

---

### ðŸ“‚ Repository Structure

* **GitHub Repository:** `alx-backend-python`
* **Directory:** `python-generators-0x00`
* **File:** `0-stream_users.py`

---

---

## ðŸ“¦ Task 2: Batch Processing Large Data

### ðŸŽ¯ Objective

Use a generator to fetch and process data from the `user_data` table in batches.

---

### ðŸ“œ Instructions

In the file `1-batch_processing.py`, implement the following:

#### ðŸ” `stream_users_in_batches(batch_size)`

* A generator function that fetches rows in batches from the database.
* Uses a database cursor and `fetchmany()` for memory-efficient streaming.

#### ðŸ§® `batch_processing(batch_size)`

* Iterates through each batch.
* Filters and prints users whose `age` is **greater than 25**.
* Uses **no more than three loops** in total.

---

### ðŸ§ª Example Output

```bash
{'user_id': '00234e50-34eb-4ce2-94ec-26e3fa749796', 'name': 'Dan Altenwerth Jr.', 'email': 'Molly59@gmail.com', 'age': 67}
{'user_id': '006bfede-724d-4cdd-a2a6-59700f40d0da', 'name': 'Glenda Wisozk', 'email': 'Miriam21@gmail.com', 'age': 119}
...
```

---

### ðŸ“‚ Repository Structure

* **GitHub Repository:** `alx-backend-python`
* **Directory:** `python-generators-0x00`
* **File:** `1-batch_processing.py`

---

---

## ðŸš€ Task 3: Lazy Loading Paginated Data

### ðŸŽ¯ Objective

Simulate fetching paginated records from the `user_data` table using a generator for **lazy loading**â€”efficiently handling large datasets by only loading one page at a time.

---

### ðŸ“œ Instructions

In `2-lazy_paginate.py`, implement the following:

#### ðŸ“„ `paginate_users(page_size, offset)`

* Fetch a specific page of data from the table using `LIMIT` and `OFFSET`.

#### ðŸŒ€ `lazy_paginate(page_size)`

* A generator that yields each page of data.
* Starts at `offset = 0` and increases until no more results are found.
* Must use **only one loop**.

---

### ðŸ§ª Example Output

```bash
{'user_id': '00234e50-34eb-4ce2-94ec-26e3fa749796', 'name': 'Dan Altenwerth Jr.', 'email': 'Molly59@gmail.com', 'age': 67}
{'user_id': '006bfede-724d-4cdd-a2a6-59700f40d0da', 'name': 'Glenda Wisozk', 'email': 'Miriam21@gmail.com', 'age': 119}
...
```

---

## ðŸ§  Task 4: Memory-Efficient Aggregation with Generators

### ðŸŽ¯ Objective

Stream user ages one at a time and calculate their average without loading all records into memory.

---

### ðŸ“œ Instructions

In `4-stream_ages.py`, implement:

#### ðŸŒ€ `stream_user_ages()`

* A generator that yields each user's `age` from the `user_data` table one by one.

#### âž— Average Age Function

* Iterate over the stream and compute the average.
* **Do not** use SQL's `AVG()` function.
* Use **no more than two loops**.

#### âœ… Output Format

```bash
Average age of users: 45.67
```

---

## ðŸ“ Repository Structure

| File                    | Purpose                                                       |
| ----------------------- | ------------------------------------------------------------- |
| `seed.py`               | Sets up the MySQL database and populates `user_data` from CSV |
| `0-stream_users.py`     | Streams user rows one by one                                  |
| `1-batch_processing.py` | Fetches and filters users in batches                          |
| `2-lazy_paginate.py`    | Implements lazy pagination using generators                   |
| `4-stream_ages.py`      | Streams and aggregates user ages efficiently                  |
| `README.md`             | Project documentation                                         |

---

## ðŸ“š Additional Resources

* [Python Generators â€“ Real Python](https://realpython.com/introduction-to-python-generators/)
* [Python Decorators](https://realpython.com/primer-on-python-decorators/)
* [Context Managers](https://docs.python.org/3/library/contextlib.html)
* [Asynchronous Programming](https://docs.python.org/3/library/asyncio.html)

---

